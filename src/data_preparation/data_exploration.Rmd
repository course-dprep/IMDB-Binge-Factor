---
title: "Data Exploration and Preparation"

author: "team 03"
date: "2024-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message= FALSE)
```


### Install necessary pacakges for data exploration

The following libraries are required for this analysis: 

- **readr**: For reading data files.

- **tidyverse**: For data manipulation and analysis.

- **dplyr**: For data wrangling and manipulation.

- **ggplot2**: For data visualization.

- **ggcorrplot** : For data visualization.


```{r install packages,include=FALSE}
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(knitr)
library(kableExtra)
```

## Introduction

This report provides the initial data exploration of the data sets. Our goal is to provide the structure of our data set,summarize key variables,and provide some basic exploratory visualizations. The data set contains information about TV series, including customer ratings, number of episodes and series duration.
 
## Overview of the Dataset and Variables

The dataset used in the project contains information about TV series and episodes from IMD Since we are interested in understanding the relationship between the length of the TV series and it's average customer ratings, we focus on the three datasets listed and described below.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.basics.tsv.gz**: Contains information about TV series titles,the start year,genres,etc.

- **title.ratings.tsv.gz**: Contains user ratings for titles.



## Description of Variables


#### title.episode.tsv.gz

```{r variables-episode,echo=FALSE}
variables_episode <- data.frame(
  Variables = c("`tconst`","`parentTconst`","`seasonNumber`", "`episodeNumber`"),
  Description = c(
    "An alphanumeric identifier unique to each episode.",
    "An alphanumeric identifier for the parent TV series of the episode.It links the episode to the overall series.",
    "The season number that the episode belongs to within the TV series.",
    "The specific episode number of the `tconst` in the TV series."
                  ),
  Class = c("String","String","Interger","Interger")
)

# Display the table using knitr::kable()
knitr::kable(variables_episode,col.names = c("Variables","Description","Class"))
```


#### title.basics.tsv.gz

```{r variables-basics,echo=FALSE}
# Create a data frame for title.basics.tsv.gz
variables_basics <- data.frame(
  Variables = c("`startYear`", "`endYear`"),
  Description = c(
    "The year the series began.",
    "TV Series end year."
                 ),
  Class = c("Integer", "Integer")
)

# Display the table using knitr::kable()
knitr::kable(variables_basics, col.names = c("Variables", "Description","Class"))

```


#### title.ratings.tsv.gz

```{r variables-ratings, echo=FALSE}
# Create a data frame for title.ratings.tsv.gz
variables_ratings <- data.frame(
  Variables = c("`tconst`", "`averageRating`"),
  Description = c(
    "Alphanumeric unique identifier of the title.",
    "Weighted average of all individual user ratings."
  ),
  Class = c("String", "Numeric")
)

# Display the table using knitr::kable()
knitr::kable(variables_ratings, col.names = c("Variables", "Description", "Class"))

```


### Loading the Datasets

Programmatically load the following datasets from IMDb:

- **title.basics.tsv.gz**: Contains information about movie and TV series titles, their start year, genres, etc.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.ratings.tsv.gz**: Contains user ratings for titles.


```{r load-datasets, echo=FALSE, warning=FALSE, message=FALSE}

# URLs to the IMDb datasets
urls <- c(
  "https://datasets.imdbws.com/title.basics.tsv.gz",
  "https://datasets.imdbws.com/title.episode.tsv.gz",
  "https://datasets.imdbws.com/title.ratings.tsv.gz"
)

# Load the datasets
datasets <- lapply(urls, read_delim, delim = '\t', na = '\\N')

# Access individual datasets
title_basics <- datasets[[1]]
title_episode <- datasets[[2]]
title_ratings <- datasets[[3]]

```


### Initial Data Exploration

#### Summary Statistics 

##### Get a quick overview of the data by using the code summary()

###### Summary statistics: title_basics


```{r summary-stats, echo=FALSE, warning=FALSE, message=FALSE}
# Summary statistics for each dataset
summary(title_basics)
```


###### Summary statistics: title_episode

```{r}
summary(title_episode)
```


###### Summary statistics: title_ratings

```{r}
summary(title_ratings)
```


#### Specific summary statistics

###### Summary statistics : title_episode

```{r specific-summary-stats, echo=FALSE, warning=FALSE, message=FALSE}

title_episode_summary <- title_episode %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst=sum(is.na(tconst)),
            missing_values_parentTconst=sum(is.na(parentTconst)),
            missing_values_seasonNumber=sum(is.na(seasonNumber)),
            missing_values_episodeNumber=sum(is.na(episodeNumber)) 
  )%>%
  print()

```


##### Summary statistics : title_ratings

```{r specific-summary-stat-2, echo=FALSE, warning=FALSE, message=FALSE}

title_ratings_summary <- title_ratings %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_averageRating = sum(is.na(averageRating)),
            missing_values_numVotes = sum(is.na(numVotes))
  ) %>%
  print()

```


##### Summary statistics : title_basics

```{r specific-summary-stat-3, echo=FALSE, warning=FALSE, message=FALSE}

title_basics_summary <- title_basics %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_titleType = sum(is.na(titleType)),
            missing_values_startYear= sum(is.na(startYear)),
            missing_values_endYear= sum(is.na(endYear))
  )%>%
  print()

```

```{r merging, echo=FALSE, warning=FALSE, message=FALSE}
# filtering TV series alone using titleType(tvEpisode) from title_basics

tv_series <- title_basics %>%
  filter(titleType == "tvEpisode")

# Merged with ratings using tconst

tv_series_ratings <- tv_series %>%
  inner_join(title_ratings, by = "tconst")


# Merging with title_episode using tconst to add parentTconst to tv_series_ratings

tv_series_ratings_with_parent <- tv_series_ratings %>%
  left_join(title_episode %>% 
              select(tconst,parentTconst), by= "tconst")

```


### Visualizations

#### TV Series Length vs Average Rating

The below plots help understand the relationship between the length of TV series and average customer ratings.Visualizations as part of our initial exploration of the data, which helps us explore trends and patterns in the data.The length of the TV series will be determined based on the number of episodes or the number of years the series was aired.


#### Plot 1: Total Episodes vs. Average Rating

```{r series-length-vs-rating-episodes, echo=FALSE, warning=FALSE, message=FALSE}

# Compute the number of episodes for each series

total_episodes <- title_episode %>%
  group_by(parentTconst) %>%
  summarize(total_episodes = n(), .groups = 'drop')  # Count episodes

# Compute and sort the number of episodes for each series
total_episodes_sorted <- title_episode %>%
  group_by(parentTconst) %>%
  summarize(total_episodes = n(), .groups = 'drop') %>%
  arrange(desc(total_episodes))

# Select and rename the columns from tv_series_ratings_with_parent
ratings_to_merge <- tv_series_ratings_with_parent[, c("parentTconst", "averageRating")]
names(ratings_to_merge)[names(ratings_to_merge) == "averageRating"] <- "averageRating_series_wise"

# Merge the two data frames
total_episodes_sorted <- merge(total_episodes_sorted, 
                               ratings_to_merge, 
                               by = "parentTconst", 
                               all.x = TRUE)

# scatter plot 
library(ggplot2)


ggplot(total_episodes_sorted, aes(x = total_episodes, y = averageRating_series_wise)) +
  geom_jitter(na.rm = TRUE, alpha = 0.3, size = 1, width = 0.1) +  # Add jitter
  labs(
    title = "Total number of Episodes vs Average Customer Ratings",
    x = "Total number of Episodes",
    y = "Average customer Rating"
  ) +
  theme_minimal()
```


##### Key insights :

- There is a  large concentration of TV shows with fewer than 2,500 episodes, with customer ratings distributed widely between 2.5 and 10.

- Series with a very high number of episodes (10,000+) seem to maintain consistent ratings but are generally few in number.


##### Inference :

- There seems to be no clear linear relationship, however series that have been running for a long time, seems to  maintain consistent ratings, possibly indicating, that long running series might have a loyal fan base warranting further analysis.


#### Plot 2: Total number of years the series was aired vs. Average Rating


```{r total-years-vs-rating, echo=FALSE, warning=FALSE, message=FALSE}

# Convert endYear to character if it is numeric
tv_series_ratings_with_parent <- tv_series_ratings_with_parent %>%
  mutate(
    endYear = as.character(endYear),  
    endYear = na_if(endYear, '\\N'),  
    endYear = as.numeric(endYear),    
    startYear = as.numeric(startYear),
    length = ifelse(is.na(endYear), 2024 - startYear, endYear - startYear) # Calculate length
  )

# Scatter plot for Length of TV Series (years) vs Average Ratings

ggplot(tv_series_ratings_with_parent, aes(x = length, y = averageRating)) +
  geom_jitter(alpha = 0.2, size = 0.7, width = 0.1, height = 0.1) +  # Further reduce point size and opacity
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Add a linear trend line
  labs(
    x = "Number of years",
    y = "Average Rating",
    title = "Number of years the TV Series aired vs. Average Rating"
  ) +
  theme_minimal(base_size = 15) +  # Increase text size for better readability
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  # Center the title and make it bold
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels
  )
```


##### Key insights : 

- Most shows are concentrated within a duration of less than 30 years.

- The red line indicates the overall average ratings across all series, it seems to remain fairly constant regardless of the no of years the show was aired.


##### Inference :

The stability in ratings for shows that have been running for a longer time, indicates that longevity may not necessarily result in a decline in viewer satisfaction. Further analysis could explain. There is no clear upward or downward trend.The plot also indicates that there might be other factors other than length of the series,might be driving customer ratings, which justifies further regression analysis.


## Data Preparation

#### Counting the number of missing values (NA) per dataset

##### To estimate amount of missing data.

```{r counting_NA, echo=FALSE, warning=FALSE, message=FALSE}
#Amount of NA's of title_basics
Sum_NA_title_basics <-sum(is.na(title_basics))

#Amount of NA's of title_episode
Sum_NA_title_episode <- sum(is.na(title_episode))

#Amount of NA's of title_ratings
Sum_NA_title_ratings <- sum(is.na(title_ratings))

#We can see that the title_ratings dataset has no NA's. 
```


### Motivation for dropping missing values (NA)

#### title_basics:

After examining the title_basics dataset, we noticed a significant number of missing values (NAs) in the columns "StartYear," "EndYear," "runtimeMinutes," and "genre." Since our project requires calculating the series length (series_length = EndYear - StartYear), it is crucial to remove rows with missing values in the "StartYear" and "EndYear" columns. Retaining rows with NAs in these columns would result in inaccurate calculations.

Additionally, the columns "runtimeMinutes" and "genre" are not necessary for our analysis, so we will drop them.

Regarding the missing values in "EndYear," there is no feasible way to recover this data in our current dataset. Because the "StartYear" and "EndYear" are specific to each TV series, it does not make sense to impute the missing values with estimates or averages, as this would compromise the accuracy of our analysis. Therefore, we will drop all rows where either "StartYear" or "EndYear" is missing to ensure the integrity of our data.


#### title_episode:

In this dataset, we observe missing values (NAs) in the columns "seasonNumber" and "episodeNumber." Since this information is specific to each TV series, we cannot impute these missing values using data from other TV shows, as doing so would introduce inaccuracies. Additionally, the missing values in these columns are missing at random. Therefore, it is important to drop rows with missing values in these columns.


#### title_ratings:

This dataset does not contain missing values(NA) 


### Revised summary statistics after dropping the missing values : title_basics 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
title_basics_no_NAs <- drop_na(title_basics)
View(title_basics_no_NAs)
summary(title_basics_no_NAs)
```


### Revised summary statistics after dropping the missing values : title_episode 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
title_episode_no_NAs <- drop_na(title_episode)
View(title_episode_no_NAs)
summary(title_episode_no_NAs) 
```



### Merging the datsets

### Revised summary statistics after dropping the missing values : title_ratings

```{r, echo=FALSE,warning=FALSE, message=FALSE}
title_ratings_no_NAs <- drop_na(title_ratings)
View(title_ratings_no_NAs)
summary(title_ratings_no_NAs) 
```


### Merging the datsets

```{r, echo=FALSE,warning=FALSE, message=FALSE}
merged_data <- title_basics_no_NAs %>%
  inner_join(title_ratings, by = "tconst") %>%
  inner_join(title_episode_no_NAs, by = c("tconst" = "parentTconst"))
```


### Engineering for new variables: 

#### total_years

A new variable is created that shows how many years a series has run, called `total_years`. This variable will be one of the independent variable in our analysis, and is created by deducting the first year that the series ran from the last year. 


#### episode_count

A new variable is created that shows the total number of episodes a series has, called `episode_count`. This variable will be one of the independent variable in our analysis.

```{r variable engineering, echo=FALSE,warning=FALSE, message=FALSE}
merged_data <- merged_data %>%
  mutate(total_years = endYear - startYear)


# Calculate the total number of episodes for each series
episode_count <- title_episode_no_NAs %>%
  group_by(parentTconst) %>%
  summarise(episode_count = n(), .groups = 'drop')  # Count the number of episodes per series


# Merge the episode count back into the merged_data
merged_data <- merged_data %>%
  left_join(episode_count, by = c("tconst" = "parentTconst"))
```


### Removing outliers 

Since our dataset is heavily skewed, the Interquartile Range (IQR) method, was used to detect outliers in the variables considered for analysis by calculating the spread of the data.The IQR measures the spread of the middle 50% data, making the data robust for analysis by handling the skewed data.This is the last step in the data preparation process.

```{r, echo=FALSE,warning=FALSE, message=FALSE}

remove_outliers_iqr <- function(column) {
  Q1 <- quantile(column, 0.25)  # Calculate the 25th percentile
  Q3 <- quantile(column, 0.75)  # Calculate the 75th percentile
  IQR_value <- IQR(column)  # Calculate the IQR (Q3 - Q1)
  lower_bound <- Q1 - 1.5 * IQR_value  # Lower bound for outliers
  upper_bound <- Q3 + 1.5 * IQR_value  # Upper bound for outliers
  column >= lower_bound & column <= upper_bound # Returns TRUE for values within bounds
}

# Columns to check for outliers
columns_to_check <- c("total_years", "episode_count", "numVotes", "averageRating")

# Apply outlier removal and combine results
cleaned_data <- merged_data[
  rowSums(sapply(merged_data[columns_to_check], remove_outliers_iqr)) == length(columns_to_check), 
]
```


#### Plot 3: Correlation Heatmap

We plot the correlation heatmap to understand the correlation between the numeric variables and understand any potential multicollinearity issues.

```{r heatmap,echo=FALSE,warning=FALSE, message=FALSE}

install.packages("ggcorrplot")
library(ggcorrplot)

# Select numeric columns for correlation matrix
numeric_columns <- cleaned_data %>%
  select(total_years, episode_count, numVotes, averageRating)

# Compute correlation matrix
corr_matrix <- cor(numeric_columns, use = "complete.obs")

# Plot the heatmap using ggcorrplot
ggcorrplot(corr_matrix, 
           method = "circle", 
           lab = TRUE, 
           title = "Correlation Heatmap")

```


##### Key insights and implications for the regression model:

###### Multicollinearity 

As we intuitively understand, moderate correlation between `total_years` and `episode_count` (0.46) led us to run two different models : model_1 with total_years & model_2 with episode_count as independent variable,while keeping `numVotes` as a control variable in both models.


### Density plots 

After removing the outliers density plots are plotted to check the distribution of data and identifying whether the variables follow a normal distribution or are skewed and the skewed variables are log transformed for regression. 


#### Plot 4: Density plot for total_years

```{r density plot total_years, echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for total_years
ggplot(cleaned_data, aes(x = total_years)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Years of TV Series",
    x = "Total Years",
    y = "Density"
  ) +
  theme_minimal()

```


##### Inference : The spikes in the density plot of total_years indicate that there are certain natural clusters. eg: series lasting 1, 5, or 10 years.Transforming this variable might distort these natural groupings.No log transformation is applied.


#### Plot 5: Density plot for episode_count

```{r density plot episode_count,echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for episode_count
ggplot(cleaned_data, aes(x = episode_count)) +
  geom_density(fill = "lightgreen", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Episodes of TV Series",
    x = "Total Episodes",
    y = "Density"
  ) +
  theme_minimal()
```


##### Inference : There is a long tail, hence `episode_count` is log transformed to stabilize variance in the regression model.


#### Plot 6: Density plot for averageRating

```{r density plot averageRating, echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for averageRating
ggplot(cleaned_data, aes(x = averageRating)) +
  geom_density(fill = "salmon", alpha = 0.5) +
  labs(
    title = "Density Plot of Average Rating",
    x = "Average Rating",
    y = "Density"
  ) +
  theme_minimal()
````

##### Inference : Log transformation required since the skeweness is extreme and the log transformation improved the homoscedasticity conditions.


#### Plot 7: Density plot for numVotes

```{r density plot numVotes,echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for numVotes
ggplot(cleaned_data, aes(x = numVotes)) +
  geom_density(fill = "orange", alpha = 0.5) +
  labs(
    title = "Density Plot of Number of Votes",
    x = "Number of Votes",
    y = "Density"
  ) +
  theme_minimal()
````

##### Inference : The density plot shows that the data is extremely skewed and hence a log transformation of `numVotes` is used in the regression analysis to avoid issues of heteroscedasticity.

