---
title: "Data Exploration and Preparation"

author: "team 03"
date: "2024-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message= FALSE)
```


### Install necessary pacakges for data exploration

The following libraries are required for this analysis: 

- **readr**: For reading data files.

- **tidyverse**: For data manipulation and analysis.

- **dplyr**: For data wrangling and manipulation.

- **ggplot2**: For data visualization.

- **ggcorrplot** : For data visualization.


```{r install packages,include=FALSE}
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(knitr)
library(kableExtra)
```

## Introduction

This report provides the initial data exploration of the data sets. Our goal is to provide the structure of our data set,summarize key variables,and provide some basic exploratory visualizations. The data set contains information about TV series, including customer ratings, number of episodes and series duration.
 
## Overview of the Dataset and Variables

The dataset used in the project contains information about TV series and episodes from IMD Since we are interested in understanding the relationship between the length of the TV series and it's average customer ratings, we focus on the three datasets listed and described below.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.basics.tsv.gz**: Contains information about TV series titles,the start year,genres,etc.

- **title.ratings.tsv.gz**: Contains user ratings for titles.



## Description of Variables


#### title.episode.tsv.gz

```{r variables-episode,echo=FALSE}
variables_episode <- data.frame(
  Variables = c("`tconst`","`parentTconst`","`seasonNumber`", "`episodeNumber`"),
  Description = c(
    "An alphanumeric identifier unique to each episode.",
    "An alphanumeric identifier for the parent TV series of the episode.It links the episode to the overall series.",
    "The season number that the episode belongs to within the TV series.",
    "The specific episode number of the `tconst` in the TV series."
                  ),
  Class = c("String","String","Interger","Interger")
)

# Display the table using knitr::kable()
knitr::kable(variables_episode,col.names = c("Variables","Description","Class"))
```


#### title.basics.tsv.gz

```{r variables-basics,echo=FALSE}
# Create a data frame for title.basics.tsv.gz
variables_basics <- data.frame(
  Variables = c("`startYear`", "`endYear`"),
  Description = c(
    "The year the series began.",
    "TV Series end year."
                 ),
  Class = c("Integer", "Integer")
)

# Display the table using knitr::kable()
knitr::kable(variables_basics, col.names = c("Variables", "Description","Class"))

```


#### title.ratings.tsv.gz

```{r variables-ratings, echo=FALSE}
# Create a data frame for title.ratings.tsv.gz
variables_ratings <- data.frame(
  Variables = c("`tconst`", "`averageRating`"),
  Description = c(
    "Alphanumeric unique identifier of the title.",
    "Weighted average of all individual user ratings."
  ),
  Class = c("String", "Numeric")
)

# Display the table using knitr::kable()
knitr::kable(variables_ratings, col.names = c("Variables", "Description", "Class"))

```


### Loading the Datasets

Programmatically load the following datasets from IMDb:

- **title.basics.tsv.gz**: Contains information about movie and TV series titles, their start year, genres, etc.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.ratings.tsv.gz**: Contains user ratings for titles.


```{r load-datasets, echo=FALSE, warning=FALSE, message=FALSE}
# Load raw datasets for initial exploration

title_basics <- read_delim(gzfile('data/title_basics.tsv.gz'), delim = "\t", na = "\\N")
title_episode <- read_delim(gzfile('data/title_episode.tsv.gz'), delim = "\t", na = "\\N")
title_ratings <- read_delim(gzfile('data/title_ratings.tsv.gz'), delim = "\t", na = "\\N")


```


### Initial Data Exploration

#### Summary Statistics of raw data

###### Summary statistics: title_basics


```{r summary-stats, echo=FALSE, warning=FALSE, message=FALSE}
# Summary statistics for each dataset
summary(title_basics)
```


###### Summary statistics: title_episode

```{r}
summary(title_episode)
```


###### Summary statistics: title_ratings

```{r}
summary(title_ratings)
```


#### Specific summary statistics of raw data

###### Summary statistics : title_episode

```{r specific-summary-stats, echo=FALSE, warning=FALSE, message=FALSE}

title_episode_summary <- title_episode %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst=sum(is.na(tconst)),
            missing_values_parentTconst=sum(is.na(parentTconst)),
            missing_values_seasonNumber=sum(is.na(seasonNumber)),
            missing_values_episodeNumber=sum(is.na(episodeNumber)) 
  )%>%
  print()

```


##### Summary statistics : title_ratings

```{r specific-summary-stat-2, echo=FALSE, warning=FALSE, message=FALSE}

title_ratings_summary <- title_ratings %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_averageRating = sum(is.na(averageRating)),
            missing_values_numVotes = sum(is.na(numVotes))
  ) %>%
  print()

```


##### Summary statistics : title_basics

```{r specific-summary-stat-3, echo=FALSE, warning=FALSE, message=FALSE}

title_basics_summary <- title_basics %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_titleType = sum(is.na(titleType)),
            missing_values_startYear= sum(is.na(startYear)),
            missing_values_endYear= sum(is.na(endYear))
  )%>%
  print()

```


#### Visualization : raw data

##### Plot : 1. Distribution of Ratings for TV Series


```{r ratings distribution raw data,echo=FALSE,warning=FALSE, message=FALSE}
# Visualize the distribution of average ratings using raw data
tv_series_raw <- title_basics %>%
  filter(titleType == "tvSeries") %>%
  inner_join(title_ratings, by = "tconst")

ggplot(tv_series_raw, aes(x = averageRating)) +
  geom_histogram(binwidth = 0.5, fill = "lightblue", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Average Ratings (Raw Data)",
    x = "Average Rating",
    y = "Frequency"
  ) +
  theme_minimal()

```

#### Inference: 






## Data Preparation


### Filtering only TV episodes from titleType, as the RQ is limited only to TV series and dropping missing observations to obtain filtered data. 


```{r,echo=FALSE, warning=FALSE, message=FALSE}

# Load filtered datasets for further analysis

title_basics_filtered <- read_csv("gen/temp/title_basics_filtered.csv")
title_episode_filtered <- read_csv("gen/temp/title_episode_filtered.csv")
title_ratings <- read_delim(gzfile('data/title_ratings.tsv.gz'), delim = "\t", na = "\\N")

```


### Motivation for dropping missing values (NA)

#### title_basics:

After examining the title_basics dataset, we noticed a significant number of missing values (NAs) in the columns "StartYear," "EndYear," "runtimeMinutes," and "genre." Since our project requires calculating the series length (series_length = EndYear - StartYear), it is crucial to remove rows with missing values in the "StartYear" and "EndYear" columns. Retaining rows with NAs in these columns would result in inaccurate calculations.

Additionally, the columns "runtimeMinutes" and "genre" are not necessary for our analysis, so we will drop them.

Regarding the missing values in "EndYear," there is no feasible way to recover this data in our current dataset. Because the "StartYear" and "EndYear" are specific to each TV series, it does not make sense to impute the missing values with estimates or averages, as this would compromise the accuracy of our analysis. Therefore, we will drop all rows where either "StartYear" or "EndYear" is missing to ensure the integrity of our data.


#### title_episode:

In this dataset, we observe missing values (NAs) in the columns "seasonNumber" and "episodeNumber." Since this information is specific to each TV series, we cannot impute these missing values using data from other TV shows, as doing so would introduce inaccuracies. Additionally, the missing values in these columns are missing at random. Therefore, it is important to drop rows with missing values in these columns.


#### title_ratings:

This dataset does not contain missing values(NA) 


### Revised summary statistics of filtered data : title_basics 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
summary(title_basics_filtered)
```


### Revised summary statistics of filtered data  : title_episode 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
summary(title_episode_filtered) 
```


### Visualizations

#### TV Series Length vs Average Rating

The below plots help understand the relationship between the length of TV series and average customer ratings.Visualizations as part of our initial exploration of the data, which helps us explore trends and patterns in the data.The length of the TV series will be determined based on the number of episodes or the number of years the series was aired.


#### Plot 2: Count of Episodes vs. Average Rating (Filtered data)


```{r series-length-vs-rating-episodes, echo=FALSE, warning=FALSE, message=FALSE}

# Compute the number of episodes for each series in filtered data
count_episodes_filtered <- title_episode_filtered %>%
  group_by(parentTconst) %>%
  summarise(count_episodes = n(), .groups = 'drop')  # Count episodes


# Merge total episodes with ratings in filtered data
filtered_episodes_ratings <- count_episodes_filtered %>%
  inner_join(title_basics_filtered[, c("tconst", "averageRating")], by = c("parentTconst" = "tconst"))

# Scatter plot for the number of episodes vs average rating (Filtered Data)
library(ggplot2)

ggplot(filtered_episodes_ratings, aes(x = count_episodes, y = averageRating)) +
  geom_jitter(alpha = 0.3, size = 1, width = 0.1, height = 0.1, color = "blue") +  
  
  labs(
    title = "Total Number of Episodes vs Average Customer Ratings (Filtered Data)",
    x = "Total Number of Episodes",
    y = "Average Customer Rating"
  ) +
  theme_minimal()

```

##### Key insights :




##### Inference :




#### Plot 3: Total number of years the series was aired vs. Average Rating (Filtered data)


```{r total-years-vs-rating, echo=FALSE, warning=FALSE, message=FALSE}

# Convert endYear to character if it is numeric, calculate the series length in filtered data

tv_series_ratings_filtered <- title_basics_filtered %>%
  left_join(title_episode_filtered %>% select(tconst, parentTconst), by = c("tconst" = "parentTconst")) %>%
  mutate(
    endYear = as.character(endYear),  
    endYear = na_if(endYear, '\\N'),  
    endYear = as.numeric(endYear),    
    startYear = as.numeric(startYear),
    length = ifelse(is.na(endYear), 2024 - startYear, endYear - startYear) 
  )

# Scatter plot for Length of TV Series (years) vs Average Ratings (Filtered Data)
ggplot(tv_series_ratings_filtered, aes(x = length, y = averageRating)) +
  geom_jitter(alpha = 0.3, size = 1, width = 0.1, height = 0.1, color = "darkgreen") +  # Adjust jitter for filtered data
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Add a linear trend line
  labs(
    x = "Number of Years Aired",
    y = "Average Rating",
    title = "Number of Years Aired vs Average Rating (Filtered Data)"
  ) +
  theme_minimal(base_size = 15) +  # Increase text size for better readability
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  # Center the title and make it bold
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for better clarity
  )

```


##### Key insights : 




##### Inference :



### Merging the datsets

After filtering and cleaning the datasets, we combine them to analyze the relationship between TV series length (number of episodes and total year aired) and customer ratings. We merge title_basics, title_episode, and title_ratings using `tconst` as the key identifier.


```{r,merging-filtered-data, echo=FALSE, warning=FALSE, message=FALSE}
# Load merged data

merged_data <- read_csv("gen/temp/merged_data.csv")

```


### Engineering for new variables: 

#### total_years

A new variable is created that shows how many years a series has run, called `total_years`. This variable will be one of the independent variable in our analysis, and is created by deducting the first year that the series ran from the last year. 


#### episode_count

A new variable is created that shows the total number of episodes a series has, called `episode_count`. This variable will be one of the independent variable in our analysis.

```{r variable engineering, echo=FALSE,warning=FALSE, message=FALSE}
# Load engineered data

engineered_data <- read_csv("gen/temp/engineered_data.csv")

```


### Removing outliers 

Since our dataset is heavily skewed, the Interquartile Range (IQR) method, was used to detect outliers in the variables considered for analysis by calculating the spread of the data.The IQR measures the spread of the middle 50% data, making the data robust for analysis by handling the skewed data.This is the last step in the data preparation process.

```{r, echo=FALSE,warning=FALSE, message=FALSE}
# Load cleaned data

cleaned_data <- read_csv("gen/output/cleaned_data.csv")

```


#### Plot 3: Correlation Heatmap

We plot the correlation heatmap to understand the correlation between the numeric variables and understand any potential multicollinearity issues.

```{r heatmap,echo=FALSE,warning=FALSE, message=FALSE}

install.packages("ggcorrplot")
library(ggcorrplot)

# Select numeric columns for correlation matrix
numeric_columns <- cleaned_data %>%
  select(total_years, episode_count, numVotes, averageRating)

# Compute correlation matrix
corr_matrix <- cor(numeric_columns, use = "complete.obs")

# Plot the heatmap using ggcorrplot
ggcorrplot(corr_matrix, 
           method = "circle", 
           lab = TRUE, 
           title = "Correlation Heatmap")

```


##### Key insights and implications for the regression model:

###### Multicollinearity 

As we intuitively understand, moderate correlation between `total_years` and `episode_count` (0.46) led us to run two different models : model_1 with total_years & model_2 with episode_count as independent variable,while keeping `numVotes` as a control variable in both models.


### Density plots 

After removing the outliers density plots are plotted to check the distribution of data and identifying whether the variables follow a normal distribution or are skewed and the skewed variables are log transformed for regression. 


#### Plot 4: Density plot for total_years

```{r density plot total_years, echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for total_years
ggplot(cleaned_data, aes(x = total_years)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Years of TV Series",
    x = "Total Years",
    y = "Density"
  ) +
  theme_minimal()

```


##### Inference : The spikes in the density plot of total_years indicate that there are certain natural clusters. eg: series lasting 1, 5, or 10 years.Transforming this variable might distort these natural groupings.No log transformation is applied.


#### Plot 5: Density plot for episode_count

```{r density plot episode_count,echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for episode_count
ggplot(cleaned_data, aes(x = episode_count)) +
  geom_density(fill = "lightgreen", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Episodes of TV Series",
    x = "Total Episodes",
    y = "Density"
  ) +
  theme_minimal()
```


##### Inference : There is a long tail, hence `episode_count` is log transformed to stabilize variance in the regression model.


#### Plot 6: Density plot for averageRating

```{r density plot averageRating, echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for averageRating
ggplot(cleaned_data, aes(x = averageRating)) +
  geom_density(fill = "salmon", alpha = 0.5) +
  labs(
    title = "Density Plot of Average Rating",
    x = "Average Rating",
    y = "Density"
  ) +
  theme_minimal()
````

##### Inference : Log transformation required since the skeweness is extreme and the log transformation improved the homoscedasticity conditions.


#### Plot 7: Density plot for numVotes

```{r density plot numVotes,echo=FALSE,warning=FALSE, message=FALSE}
# Density plot for numVotes
ggplot(cleaned_data, aes(x = numVotes)) +
  geom_density(fill = "orange", alpha = 0.5) +
  labs(
    title = "Density Plot of Number of Votes",
    x = "Number of Votes",
    y = "Density"
  ) +
  theme_minimal()
````

##### Inference : The density plot shows that the data is extremely skewed and hence a log transformation of `numVotes` is used in the regression analysis to avoid issues of heteroscedasticity.

