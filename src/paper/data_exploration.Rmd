---
title: "Data Exploration and Preparation"

author: "team 03"
date: "2024-09-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message= FALSE,fig.width = 8,fig.height = 6,fig.align = 'center',dpi=300,dev='png',fig.retina = 2, fig.cap = NULL)
```


#### 0. Install necessary pacakges for data exploration

The following libraries are required for this analysis: 

- **readr**: For reading data files.

- **tidyverse**: For data manipulation and analysis.

- **dplyr**: For data wrangling and manipulation.

- **ggplot2**: For data visualization.

- **ggcorrplot** : For data visualization.


```{r install packages,include=FALSE}
library(readr)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(knitr)
library(kableExtra)
library(here)
```

## 1. Introduction

This report provides the initial data exploration of the data sets. Our goal is to provide the structure of our data set,summarize key variables,and provide some basic exploratory visualizations. The data set contains information about TV series, including customer ratings, number of episodes and series duration.
 
### 1.1. Overview of the Dataset and Variables

The dataset used in the project contains information about TV series and episodes from IMD Since we are interested in understanding the relationship between the length of the TV series and it's average customer ratings, we focus on the three datasets listed and described below.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.basics.tsv.gz**: Contains information about TV series titles,the start year,genres,etc.

- **title.ratings.tsv.gz**: Contains user ratings for titles.



## 2. Description of Variables


### 2.1. title.episode.tsv.gz

```{r variables-episode,echo=FALSE}
variables_episode <- data.frame(
  Variables = c("`tconst`","`parentTconst`","`seasonNumber`", "`episodeNumber`"),
  Description = c(
    "An alphanumeric identifier unique to each episode.",
    "An alphanumeric identifier for the parent TV series of the episode.It links the episode to the overall series.",
    "The season number that the episode belongs to within the TV series.",
    "The specific episode number of the `tconst` in the TV series."
                  ),
  Class = c("String","String","Interger","Interger")
)

# Display the table using knitr::kable()
knitr::kable(variables_episode,col.names = c("Variables","Description","Class"))
```


### 2.2. title.basics.tsv.gz

```{r variables-basics,echo=FALSE}
# Create a data frame for title.basics.tsv.gz
variables_basics <- data.frame(
  Variables = c("`startYear`", "`endYear`"),
  Description = c(
    "The year the series began.",
    "TV Series end year."
                 ),
  Class = c("Integer", "Integer")
)

# Display the table using knitr::kable()
knitr::kable(variables_basics, col.names = c("Variables", "Description","Class"))

```


### 2.3. title.ratings.tsv.gz

```{r variables-ratings, echo=FALSE}
# Create a data frame for title.ratings.tsv.gz
variables_ratings <- data.frame(
  Variables = c("`tconst`", "`averageRating`"),
  Description = c(
    "Alphanumeric unique identifier of the title.",
    "Weighted average of all individual user ratings."
  ),
  Class = c("String", "Numeric")
)

# Display the table using knitr::kable()
knitr::kable(variables_ratings, col.names = c("Variables", "Description", "Class"))

```


## 3. Datasets Description


- **title.basics.tsv.gz**: Contains information about movie and TV series titles, their start year, genres, etc.

- **title.episode.tsv.gz**: Contains information about individual episodes of TV series.

- **title.ratings.tsv.gz**: Contains user ratings for titles.


```{r load-datasets, echo=FALSE, warning=FALSE, message=FALSE}
# Load raw datasets for initial exploration

title_basics <- read_delim(gzfile('../../data/title_basics.tsv.gz'), delim = "\t", na = "\\N")
title_episode <- read_delim(gzfile('../../data/title_episode.tsv.gz'), delim = "\t", na = "\\N")
title_ratings <- read_delim(gzfile('../../data/title_ratings.tsv.gz'), delim = "\t", na = "\\N")


```


## 4. Initial Data Exploration: Raw Data

#### title_basics


```{r summary-stats, echo=FALSE, warning=FALSE, message=FALSE}
# Summary statistics for each dataset
summary(title_basics)
```


#### title_episode

```{r}
summary(title_episode)
```

#### title_ratings

```{r}
summary(title_ratings)
```


### 4.1. Specific summary statistics of raw data

#### title_episode


```{r specific-summary-stats, echo=FALSE, warning=FALSE, message=FALSE}
library(knitr)
title_episode_summary <- title_episode %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst=sum(is.na(tconst)),
            missing_values_parentTconst=sum(is.na(parentTconst)),
            missing_values_seasonNumber=sum(is.na(seasonNumber)),
            missing_values_episodeNumber=sum(is.na(episodeNumber)) 
  )
kable(title_episode_summary)
```


#### title_ratings

```{r specific-summary-stat-2, echo=FALSE, warning=FALSE, message=FALSE}

title_ratings_summary <- title_ratings %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_averageRating = sum(is.na(averageRating)),
            missing_values_numVotes = sum(is.na(numVotes))
  ) 
kable(title_ratings_summary)

```


#### title_basics

```{r specific-summary-stat-3, echo=FALSE, warning=FALSE, message=FALSE}

title_basics_summary <- title_basics %>%
  summarise(num_rows=n(),
            num_cols=ncol(.),
            missing_values_tconst = sum(is.na(tconst)),
            missing_values_titleType = sum(is.na(titleType)),
            missing_values_startYear= sum(is.na(startYear)),
            missing_values_endYear= sum(is.na(endYear))
  )
kable(title_basics_summary)

```


## 5. Visualization : raw data

### Plot : 1. Distribution of Ratings for TV Series (raw data)


```{r ratings distribution raw data,echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}
# Visualize the distribution of average ratings using raw data
tv_series_raw <- title_basics %>%
  filter(titleType == "tvSeries") %>%
  inner_join(title_ratings, by = "tconst")

ggplot(tv_series_raw, aes(x = averageRating)) +
  geom_histogram(binwidth = 0.5, fill = "lightgreen", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Average Ratings (Raw Data)",
    x = "Average Rating",
    y = "Frequency"
  ) +
  theme_minimal()

```

#### Inference: 
The histogram is slightly skewed towards the right indicating that most of the ratings fall between the range of 5 to 8.The histogram represent all types of `titleType` like shorts,videos,tvEpisodes,tvseries,documentary etc. 


## 6. Data Preparation

### 6.1. Filtering only TV series from titleType

As the Research Question is limited only to TV series other `titleType` are dropped. 


```{r,echo=FALSE, warning=FALSE, message=FALSE}

# Load filtered datasets for further analysis

title_basics_filtered <- read_csv("../../gen/temp/title_basics_filtered.csv")
title_episode_filtered <- read_csv("../../gen/temp/title_episode_filtered.csv")
title_ratings <- read_delim(gzfile('../../data/title_ratings.tsv.gz'), delim = "\t", na = "\\N")

```

### 6.2. Motivation for dropping missing values (NA)

#### title_basics:

After examining the title_basics dataset, it was noticed that a  significant number of missing values (NAs) occur in the columns "StartYear," "EndYear," "runtimeMinutes," and "genre." Since our project requires calculating the series length (series_length = EndYear - StartYear), it is crucial to impute rows with missing values in the "StartYear" and "EndYear" columns. But imputing for `startYear` is inherently misleading, hence imputation is done only for the `endYear`. A group imputation startegy is used to impute values for missing `endYear`.The `startYear` is grouped into bins, each having a 15 year interval.This captures temporal trends while reducing variance. The median value of the `endYear` for each group of `startYear` is used to impute the missing `endYear` values.Since, `startYear` gives information about when the show began, it is assumed that shows starting around the same period are likely to end  around the same time.Additionally, the columns "runtimeMinutes" and "genre" are not necessary for our analysis, so it is dropped.


#### title_episode:

In this dataset, we observe missing values (NAs) in the columns "seasonNumber" and "episodeNumber." Since this information is specific to each TV series, we cannot impute these missing values using data from other TV shows, as doing so would introduce inaccuracies. Additionally, the missing values in these columns are missing at random. Therefore, it is important to drop rows with missing values in these columns.


#### title_ratings:

This dataset does not contain missing values(NA) 


### 6.3. Revised summary statistics : filtered data 

#### title_basics 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
summary(title_basics_filtered)
```


#### title_episode 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
summary(title_episode_filtered) 
```


### 6.4. Merging the datsets

After filtering and cleaning the datasets, we combine them to analyze the relationship between TV series length (number of episodes and total years aired) and customer ratings. We merge title_basics, title_episode, and title_ratings using `tconst` as the key identifier.


```{r,merging-filtered-data, echo=FALSE, warning=FALSE, message=FALSE}
# Load merged data
merged_data <- read_csv("../../gen/temp/merged_data.csv")
```


### 6.5. Engineering for new variables: 

#### total_years

A new variable is created that shows how many years a series has run, called `total_years`. This variable will be one of the independent variable in our analysis, and is created by deducting the first year that the series ran from the last year. 


#### episode_count

A new variable is created that shows the total number of episodes a series has, called `episode_count`. This variable will be one of the independent variable in our analysis.

```{r variable engineering, echo=FALSE,warning=FALSE, message=FALSE}
# Load engineered data
engineered_data <- read_csv("../../gen/temp/engineered_data.csv")
```


### 6.6. Removing outliers 

Since our dataset is heavily skewed, the Interquartile Range (IQR) method, was used to detect outliers in the variables considered for analysis by calculating the spread of the data.The IQR measures the spread of the middle 50% data, making the data robust for analysis by handling the skewed data.This is the last step in the data preparation process.

```{r, echo=FALSE,warning=FALSE, message=FALSE}
# Load cleaned data
cleaned_data <- read_csv("../../gen/output/cleaned_data.csv")
```


## 7. Visualizations

### 7.1. Plots for TV Series Length vs Average Rating

The below plots help understand the relationship between the length of TV series and average customer ratings.Visualizations as part of our initial exploration of the data, which helps us explore trends and patterns in the data.The length of the TV series will be determined based on the number of episodes or the number of years the series was aired.


### Plot 2: Count of Episodes vs. Average Rating (cleaned data)

```{r series-length-vs-rating-episodes, echo=FALSE, warning=FALSE, message=FALSE,fig.cap=""}
# Scatter plot for count of episodes vs average rating (cleaned data)
library(ggplot2)

ggplot(cleaned_data, aes(x = episode_count, y = averageRating)) +
  geom_jitter(alpha = 0.6, size = 0.6, width = 0.2, height = 0.2, color ="gray40") +  
  geom_smooth(method="lm", color ="darkred", se=FALSE, size=1)+
  
  labs(
    title = "Count of Episodes vs Average Ratings (Cleaned data)",
    x = "Total Number of Episodes",
    y = "Average Customer Rating"
  ) +
  theme_minimal(base_size = 15)+
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.text.x = element_text(angle = 45,hjust = 1)
        )
```

#### Key insights :




#### Inference :




### Plot 3: Total years the series was aired vs. Average Rating (cleaned data)


```{r total-years-vs-rating, echo=FALSE, warning=FALSE, message=FALSE,fig.cap=""}

# Scatter plot for Length of TV Series (years) vs Average Ratings (Filtered Data)
ggplot(cleaned_data, aes(x = total_years, y = averageRating)) +
  geom_jitter(alpha = 0.6, size = 0.6, width = 0.2, height = 0.2, color = "darkgreen") +  
  geom_smooth(method = "lm", color = "red", se = FALSE) +  
  labs(
    x = "Number of Years Aired",
    y = "Average Rating",
    title = "Number of Years Aired vs Average Rating (cleaned data)"
  ) +
  theme_minimal(base_size = 15) +  
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  
    axis.text.x = element_text(angle = 45, hjust = 1)  
  )
```


#### Key insights : 




#### Inference :



### 7.2.  Multicollinearity 

### Key insights and implications for the regression model:

As we intuitively understand, moderate correlation between `total_years` and `episode_count` (0.46) led us to run two different models : model_1 with total_years & model_2 with episode_count as independent variable,while keeping `numVotes` as a control variable in both models.


### Plot 4: Correlation Heatmap

We plot the correlation heatmap to understand the correlation between the numeric variables and understand any potential multicollinearity issues.

```{r heatmap,echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}

install.packages("ggcorrplot")
library(ggcorrplot)

# Select numeric columns for correlation matrix
numeric_columns <- cleaned_data %>%
  select(total_years, episode_count, numVotes, averageRating)

# Compute correlation matrix
corr_matrix <- cor(numeric_columns, use = "complete.obs")

# Plot the heatmap using ggcorrplot
ggcorrplot(corr_matrix, 
           method = "circle", 
           lab = TRUE, 
           title = "Correlation Heatmap")

```


### 7.3. Density plots 

After removing the outliers density plots are plotted to check the distribution of data and identifying whether the variables follow a normal distribution or are skewed and the skewed variables are log transformed for regression. 


### Plot 5: Density plot for total_years

```{r density plot total_years, echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}
# Density plot for total_years
ggplot(cleaned_data, aes(x = total_years)) +
  geom_density(fill = "skyblue", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Years of TV Series",
    x = "Total Years",
    y = "Density"
  ) +
  theme_minimal()

```


#### Inference : 
The spikes in the density plot of total_years indicate that there are certain natural clusters. eg: series lasting 1, 5, or 10 years.Transforming this variable might distort these natural groupings.No log transformation is applied.


### Plot 6: Density plot for episode_count

```{r density plot episode_count,echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}
# Density plot for episode_count
ggplot(cleaned_data, aes(x = episode_count)) +
  geom_density(fill = "lightgreen", alpha = 0.5) +
  labs(
    title = "Density Plot of Total Episodes of TV Series",
    x = "Total Episodes",
    y = "Density"
  ) +
  theme_minimal()
```


#### Inference : 
There is a long tail, hence `episode_count` is log transformed to stabilize variance in the regression model.


### Plot 7: Density plot for averageRating

```{r density plot averageRating, echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}
# Density plot for averageRating
ggplot(cleaned_data, aes(x = averageRating)) +
  geom_density(fill = "salmon", alpha = 0.5) +
  labs(
    title = "Density Plot of Average Rating",
    x = "Average Rating",
    y = "Density"
  ) +
  theme_minimal()
```

#### Inference : 
Log transformation required since the skeweness is extreme and the log transformation improved the homoscedasticity conditions.


### Plot 8: Density plot for numVotes

```{r density plot numVotes,echo=FALSE,warning=FALSE, message=FALSE,fig.cap=""}
# Density plot for numVotes
ggplot(cleaned_data, aes(x = numVotes)) +
  geom_density(fill = "orange", alpha = 0.5) +
  labs(
    title = "Density Plot of Number of Votes",
    x = "Number of Votes",
    y = "Density"
  ) +
  theme_minimal()
```

#### Inference : 
The density plot shows that the data is extremely skewed and hence a log transformation of `numVotes` is used in the regression analysis to avoid issues of heteroscedasticity.

